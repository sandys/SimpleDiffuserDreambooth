{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will run on Pytorch 1.13 and CUDA 11.6+\n",
    "#I have seen this having major issues on 1.12 and lower CUDA. please do not try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XU7NuMAA2drw",
    "outputId": "7eb9b063-664f-4a42-e960-728ec9608c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090, 24576 MiB, 24267 MiB\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.4ubuntu1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "#@markdown Check type of GPU and VRAM available.\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
    "!apt install -y build-essential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzM7j0ZSc_9c"
   },
   "source": [
    "https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnTMyW41cC1E"
   },
   "source": [
    "## Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aLWXPZqjsZVV"
   },
   "outputs": [],
   "source": [
    "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
    "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aLWXPZqjsZVV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq diffusers\n",
    "%pip install -q -U --pre triton\n",
    "%pip install -q accelerate==0.15.0 transformers ftfy bitsandbytes gradio natsort\n",
    "%pip install -q scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes==0.35\n",
      "  Downloading bitsandbytes-0.35.0-py3-none-any.whl (62.5 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62.5 MB 130.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.35.4\n",
      "    Uninstalling bitsandbytes-0.35.4:\n",
      "      Successfully uninstalled bitsandbytes-0.35.4\n",
      "Successfully installed bitsandbytes-0.35.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes==0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH']='/usr/lib/x86_64-linux-gnu/:/opt/conda/lib/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 116\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ DEBUG INFORMATION +++++++++++++++++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "++++++++++ POTENTIALLY LIBRARY-PATH-LIKE ENV VARS ++++++++++\n",
      "'JPY_SESSION_NAME': 'proj/275c07eb-95cc-4571-9fa2-45f5dfc2e0eb'\n",
      "'LD_LIBRARY_PATH': '/usr/lib/x86_64-linux-gnu/:/opt/conda/lib/'\n",
      "'MPLBACKEND': 'module://matplotlib_inline.backend_inline'\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "WARNING: Please be sure to sanitize sensible info from any such env vars!\n",
      "\n",
      "++++++++++++++++++++++++++ OTHER +++++++++++++++++++++++++++\n",
      "COMPILED_WITH_CUDA = True\n",
      "COMPUTE_CAPABILITIES_PER_GPU = ['8.6']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++ DEBUG INFO END ++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Running a quick check that:\n",
      "    + library is importable\n",
      "    + CUDA function is callable\n",
      "\n",
      "SUCCESS!\n",
      "Installation was successful!\n"
     ]
    }
   ],
   "source": [
    "!python -m bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "y4lqqWT_uxD2"
   },
   "outputs": [],
   "source": [
    "#@title Login to HuggingFace ðŸ¤—\n",
    "\n",
    "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox if you agree. You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
    "# https://huggingface.co/settings/tokens\n",
    "!mkdir -p ~/.huggingface\n",
    "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
    "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfTlc8Mqb8iH"
   },
   "source": [
    "### Install xformers from precompiled wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cutlass\n",
      "  Downloading cutlass-0.0.1.tar.gz (64 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: cutlass\n",
      "  Building wheel for cutlass (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cutlass: filename=cutlass-0.0.1-py3-none-any.whl size=70843 sha256=4c6362a295584ae13249e06dd80c3f7f129c14fd26e5d3f3d4aadd2c90115ecd\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/cf/04/bdc024e49cdca5eebee0f463bcd9bd370933704eed50d1fe0a\n",
      "Successfully built cutlass\n",
      "Installing collected packages: cutlass\n",
      "Successfully installed cutlass-0.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 145 kB 16.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: ninja\n",
      "Successfully installed ninja-1.11.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cutlass\n",
    "%pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: xformers 0.0.15.dev0+affe4da.d20221210\n",
      "Uninstalling xformers-0.0.15.dev0+affe4da.d20221210:\n",
      "  Successfully uninstalled xformers-0.0.15.dev0+affe4da.d20221210\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall xformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6dcjPnnaiCn",
    "outputId": "ac7dc3db-27a2-4dd4-963e-4d77dc313a5d"
   },
   "outputs": [],
   "source": [
    "# If precompiled wheels don't work, install it with the following command.\n",
    "#Go to here, find your GPU (probably in the Quadro/RTX or GeForce/TITAN sections), and note the compute compatibility version number listed for your GPU.\n",
    "#https://developer.nvidia.com/cuda-gpus#compute\n",
    "#https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/3525#discussioncomment-3965024\n",
    "\n",
    "#https://github.com/Azadehkhojandi/PantryImageSegmentation/blob/043d2553238a8ce1805f3ef5856e26becfce3c3f/pytorch-mask-rcnn/.ipynb_checkpoints/InstallPyTorchSourceCUDA-checkpoint.ipynb\n",
    "#https://github.com/facebookresearch/xformers/blob/main/.github/workflows/wheels.yml\n",
    "\n",
    "%env TORCH_CUDA_ARCH_LIST = 8.6\n",
    "%env FORCE_CUDA = 1\n",
    "%env XFORMERS_BUILD_TYPE = Release\n",
    "%env CUDA_VISIBLE_DEVICES = 0 \n",
    "%env MAX_JOBS = 1\n",
    "%env DISTUTILS_USE_SDK = 1\n",
    "%pip install --no-clean git+https://github.com/facebookresearch/xformers#egg=xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0NV324ZcL9L"
   },
   "source": [
    "## Settings and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "def reset_folder(path):\n",
    "    if os.path.isdir(path):\n",
    "      shutil.rmtree(path)\n",
    "    os.makedirs(path,exist_ok=True)\n",
    "\n",
    "    \n",
    "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
    "#MODEL_NAME = \"CompVis/stable-diffusion-v1-4\"  #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (375962886.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [25]\u001b[0;36m\u001b[0m\n\u001b[0;31m    TEST_IMAGES_DIR =\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "INSTANCE = \"sukh02\"#@param {type:\"string\"}\n",
    "#INSTANCE_DIR = \"/content/data/\"+INSTANCE \n",
    "INSTANCE_DIR = \"data/zwx\"\n",
    "\n",
    "\n",
    "CLASS = \"person\" #@param {type:\"string\"}\n",
    "#CLASS_DIR = \"/content/data/\"+CLASS\n",
    "CLASS_DIR = \"data/person\"\n",
    "\n",
    "\n",
    "#OUTPUT_DIR = \"/content/stable_diffusion_weights/\" + INSTANCE\n",
    "OUTPUT_DIR = \"data/stable_diffusion_weights/zwx2\" #@param {type:\"string\"}\n",
    "TEST_IMAGES_DIR =  \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_folder(INSTANCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_folder(CLASS_DIR)\n",
    "reset_folder(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn5ILIyDJIcX"
   },
   "source": [
    "# Start Training\n",
    "\n",
    "Use the table below to choose the best flags based on your memory and speed requirements. Tested on Tesla T4 GPU.\n",
    "\n",
    "\n",
    "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
    "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
    "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
    "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
    "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
    "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
    "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
    "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
    "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
    "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
    "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ioxxvHoicPs"
   },
   "source": [
    "Add `--gradient_checkpointing` flag for around 9.92 GB VRAM usage.\n",
    "\n",
    "remove `--use_8bit_adam` flag for full precision. Requires 15.79 GB with `--gradient_checkpointing` else 17.8 GB.\n",
    "\n",
    "remove `--train_text_encoder` flag to reduce memory usage further, degrades output quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "form",
    "id": "32gYIDDR1aCp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Stable-Diffusion-Regularization-Images-person_ddim'...\n",
      "remote: Enumerating objects: 1503, done.\u001b[K\n",
      "remote: Total 1503 (delta 0), reused 0 (delta 0), pack-reused 1503\u001b[K\n",
      "Receiving objects: 100% (1503/1503), 657.41 MiB | 17.86 MiB/s, done.\n",
      "Checking out files: 100% (1500/1500), done.\n"
     ]
    }
   ],
   "source": [
    "#@markdown download regularization data\n",
    "dataset=\"person_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"blonde_woman\"]\n",
    "!git clone  https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "32gYIDDR1aCp"
   },
   "outputs": [],
   "source": [
    "!mkdir -p data/person\n",
    "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* data/person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjcSXTp-u-Eg"
   },
   "outputs": [],
   "source": [
    "!accelerate launch train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --class_data_dir=$CLASS_DIR \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "  --instance_prompt=$INSTANCE \\\n",
    "  --class_prompt=$CLASS\\\n",
    "  --seed=1337 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --train_text_encoder \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --use_8bit_adam \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --gradient_checkpointing \\\n",
    "  --learning_rate=1e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_class_images=1500 \\\n",
    "  --sample_batch_size=4 \\\n",
    "  --max_train_steps=2000 \\\n",
    "  --save_interval=10_000 \\\n",
    "  --save_sample_prompt=$CLASS\n",
    "\n",
    "# Reduce the `--save_interval` to lower than `--max_train_steps` to save weights from intermediate steps.\n",
    "# `--save_sample_prompt` can be same as `--instance_prompt` to generate intermediate samples (saved along with weights in samples directory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5V8wgU0HN-Kq",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Convert weights to ckpt to use in web UIs like AUTOMATIC1111."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "dcXzsUyG1aCy"
   },
   "outputs": [],
   "source": [
    "#@markdown Run conversion.\n",
    "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
    "\n",
    "half_arg = \"\"\n",
    "#@markdown  Whether to convert to fp16, takes half the space (2GB).\n",
    "fp16 = True #@param {type: \"boolean\"}\n",
    "if fp16:\n",
    "    half_arg = \"--half\"\n",
    "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
    "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToNG4fd_dTbF"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/huggingface_hub/file_download.py:594: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n",
      "Downloading: 57.6kB [00:00, 26.6MB/s]                                           \n",
      "You have disabled the safety checker for <class 'diffusers_modules.git.lpw_stable_diffusion.StableDiffusionLongPromptWeightingPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:12<00:00,  2.39it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/proj/infer.py\", line 100, in <module>\n",
      "    img.save('images/'+str(i).zfill(4)+folder_time+'.jpg')\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/PIL/Image.py\", line 2209, in save\n",
      "    fp = builtins.open(filename, \"w+b\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'images/00002022-12-12_03-11-33_PM.jpg'\n"
     ]
    }
   ],
   "source": [
    "!python infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
